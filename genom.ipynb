{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neptune: Executing in Offline Mode.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import Sampler\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import pathlib\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import PIL\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision.models import resnet\n",
    "import sys\n",
    "import pandas as pd\n",
    "# from neptune import Context\n",
    "from sklearn.metrics import f1_score\n",
    "from neptune import Context\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch import optim, save\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet50\n",
    "\n",
    "from ignite.engine import Events\n",
    "from ignite.engine import create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.metrics import CategoricalAccuracy, Recall, Precision\n",
    "from ignite.metrics import Loss\n",
    "import numpy as np\n",
    "RANDOM_SEED = 666\n",
    "\n",
    "LABEL_MAP = {\n",
    "0: \"Nucleoplasm\" ,\n",
    "1: \"Nuclear membrane\"   ,\n",
    "2: \"Nucleoli\"   ,\n",
    "3: \"Nucleoli fibrillar center\",   \n",
    "4: \"Nuclear speckles\"   ,\n",
    "5: \"Nuclear bodies\"   ,\n",
    "6: \"Endoplasmic reticulum\"   ,\n",
    "7: \"Golgi apparatus\"  ,\n",
    "8: \"Peroxisomes\"   ,\n",
    "9:  \"Endosomes\"   ,\n",
    "10: \"Lysosomes\"   ,\n",
    "11: \"Intermediate filaments\"  , \n",
    "12: \"Actin filaments\"   ,\n",
    "13: \"Focal adhesion sites\"  ,\n",
    "14: \"Microtubules\"   ,\n",
    "15: \"Microtubule ends\"   ,\n",
    "16: \"Cytokinetic bridge\"   ,\n",
    "17: \"Mitotic spindle\"  ,\n",
    "18: \"Microtubule organizing center\",  \n",
    "19: \"Centrosome\",\n",
    "20: \"Lipid droplets\"   ,\n",
    "21: \"Plasma membrane\"  ,\n",
    "22: \"Cell junctions\"   ,\n",
    "23: \"Mitochondria\"   ,\n",
    "24: \"Aggresome\"   ,\n",
    "25: \"Cytosol\" ,\n",
    "26: \"Cytoplasmic bodies\",\n",
    "27: \"Rods & rings\"}\n",
    "\n",
    "\n",
    "ctx = Context()\n",
    "class MultiBandMultiLabelDataset(Dataset):\n",
    "    BANDS_NAMES = ['_red.png','_green.png','_blue.png','_yellow.png']\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images_df)\n",
    "    \n",
    "    def __init__(self, images_df, \n",
    "                 base_path, \n",
    "                 image_transform,\n",
    "                 augmentator=None,\n",
    "                 train_mode=True,\n",
    "                 n_channels=4\n",
    "                ):\n",
    "        if not isinstance(base_path, pathlib.Path):\n",
    "            base_path = pathlib.Path(base_path)\n",
    "            \n",
    "        self.images_df = images_df.copy()\n",
    "        self.image_transform = image_transform\n",
    "        self.augmentator = augmentator\n",
    "        self.images_df.Id = self.images_df.Id.apply(lambda x: base_path / x)\n",
    "        self.mlb = MultiLabelBinarizer(classes=list(LABEL_MAP.keys()))\n",
    "        self.train_mode = train_mode\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "                                      \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        y = None\n",
    "        X = self._load_multiband_image(index)\n",
    "        if self.train_mode:\n",
    "            y = self._load_multilabel_target(index)\n",
    "        \n",
    "        # augmentator can be for instance imgaug augmentation object\n",
    "        if self.augmentator is not None:\n",
    "            X = self.augmentator(X)\n",
    "            \n",
    "        X = self.image_transform(X)\n",
    "            \n",
    "        return X, y \n",
    "        \n",
    "    def _load_multiband_image(self, index):\n",
    "        row = self.images_df.iloc[index]\n",
    "        image_bands = []\n",
    "        for band_name in self.BANDS_NAMES:\n",
    "            p = str(row.Id.absolute()) + band_name\n",
    "            pil_channel = PIL.Image.open(p)\n",
    "            image_bands.append(pil_channel)\n",
    "            \n",
    "        # lets pretend its a RBGA image to support 4 channels\n",
    "        band4image = PIL.Image.merge('RGBA', bands=image_bands[:])\n",
    "        return band4image\n",
    "    \n",
    "    \n",
    "    def _load_multilabel_target(self, index):\n",
    "        return list(map(int, self.images_df.iloc[index].Target.split(' ')))\n",
    "    \n",
    "        \n",
    "    def collate_func(self, batch):\n",
    "        labels = None\n",
    "        images = [x[0] for x in batch]\n",
    "        \n",
    "        if self.train_mode:\n",
    "            labels = [x[1] for x in batch]\n",
    "            labels_one_hot  = self.mlb.fit_transform(labels)\n",
    "            labels = torch.FloatTensor(labels_one_hot)\n",
    "            \n",
    "        image_stack = torch.stack(images)\n",
    "        image_stack[:,0,:,:] + image_stack[:,3,:,:] / 2\n",
    "        image_stack[:,1,:,:] + image_stack[:,3,:,:] / 2\n",
    "        image_stack = image_stack[:,:3,:,:]\n",
    "\n",
    "        \n",
    "        \n",
    "        return image_stack, labels\n",
    "\n",
    "def get_model(n_classes, image_channels=4):\n",
    "    model = resnet50(pretrained=False)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "    inft = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features=inft, out_features=n_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    model.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "    \n",
    "    return model  \n",
    "\n",
    "\n",
    "def train(trainer, train_loader, test_loader, epochs):\n",
    "    @trainer.on(Events.ITERATION_COMPLETED)\n",
    "    def log_training_loss(engine):\n",
    "        iter = (engine.state.iteration - 1) % len(train_loader) + 1\n",
    "#         ctx.channel_send('loss', engine.state.output)\n",
    "        if iter % 100 == 0:\n",
    "            print(\"Epoch[{}] Iteration[{}/{}] Loss: {:.2f}\"\n",
    "                  \"\".format(engine.state.epoch, iter, len(train_loader), engine.state.output))\n",
    "\n",
    "    @trainer.on(Events.EPOCH_COMPLETED)\n",
    "    def log_training_results(engine):\n",
    "        evaluator.run(test_loader)\n",
    "        metrics = evaluator.state.metrics\n",
    "        avg_nll = metrics['loss']\n",
    "        print(\"Training Results - Epoch: {}  Avg loss: {:.2f}\"\n",
    "              .format(engine.state.epoch, avg_nll))\n",
    "        save(model, '/home/i008/model_{}_{}.torch'.format(engine.state.epoch, avg_nll))\n",
    "    trainer.run(train_loader, max_epochs=epochs)\n",
    "    \n",
    "    return model \n",
    "    \n",
    "\n",
    "# Eval\n",
    "def evaluate(model, test_loader, threshold=0.2):\n",
    "    all_preds = []\n",
    "    true = []\n",
    "    model.eval()\n",
    "    for b in test_loader:\n",
    "        X, y = b\n",
    "        X, y = X.cuda(), y.cuda()\n",
    "        pred = model(X)\n",
    "        all_preds.append(pred.sigmoid().cpu().data.numpy())\n",
    "        true.append(y.cpu().data.numpy())\n",
    "        \n",
    "        \n",
    "    P = np.concatenate(all_preds)\n",
    "    R = np.concatenate(true)\n",
    "    \n",
    "    for t in [0.05, 0.1, 0.15, 0.2, 0.25]:\n",
    "        f1 = f1_score(P>t, R, average='macro')\n",
    "        print(f1)\n",
    "    return f1\n",
    "    \n",
    "\n",
    "## Submission\n",
    "def predict_submission(model, submission_loader):\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "    for i, b in enumerate(submission_loader):\n",
    "        if i % 100: print('processing batch {}/{}'.format(i, len(submission_loader)))\n",
    "        X, _ = b\n",
    "        X = X.cuda()\n",
    "        pred = model(X)\n",
    "        all_preds.append(pred.sigmoid().cpu().data.numpy())\n",
    "    return np.concatenate(all_preds)\n",
    "        \n",
    "         \n",
    "def make_submission_file(sample_submission_df, predictions):\n",
    "    submissions = []\n",
    "    for row in predictions:\n",
    "        subrow = ' '.join(list([str(i) for i in np.nonzero(row)[0]]))\n",
    "        submissions.append(subrow)\n",
    "    \n",
    "    sample_submission_df['Predicted'] = submissions\n",
    "    sample_submission_df.to_csv('submission.csv', index=None)\n",
    "    \n",
    "    \n",
    "    return sample_submission_df\n",
    "\n",
    "                                                                \n",
    "                                                                    \n",
    "def get_resnet(n_classes=28, resnet_version='resnet50', image_channels=3, pretrained=True):\n",
    "    \"\"\"\n",
    "    :param n_classes:\n",
    "    :param resnet_version in ['resnet152', 'resnet50', 'resnet18', 'resnet101']\n",
    "    :param image_channels:\n",
    "    :param pretrained:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert resnet_version in ['resnet' + str(i) for i in [18, 50, 101, 152]]\n",
    "    model = getattr(resnet, resnet_version)(pretrained=pretrained)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "    inft = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features=inft, out_features=n_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    if image_channels is not 3:\n",
    "        model.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                bias=False)\n",
    "\n",
    "    return model                                                                    \n",
    "    \n",
    "PATH_TO_IMAGES = '/media/i008/duzy/genom/train/'\n",
    "PATH_TO_TEST_IMAGES = '/media/i008/duzy/genom/test/'\n",
    "PATH_TO_META = '/media/i008/duzy/genom/train.csv'\n",
    "SAMPLE_SUBMI = '/media/i008/duzy/genom/sample_submission.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 666\n",
    "DEV_MODE = False\n",
    "    \n",
    "df = pd.read_csv(PATH_TO_META)\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=SEED)\n",
    "df_submission = pd.read_csv(SAMPLE_SUBMI)\n",
    "\n",
    "if DEV_MODE:\n",
    "    df_train, df_test = df_train[:1000], df_test[:100]\n",
    "    \n",
    "\n",
    "SIZE = 256\n",
    "BS= 16\n",
    "\n",
    "MEAN = [0.485, 0.456, 0.406]\n",
    "STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "image_transform_train = transforms.Compose([\n",
    "           transforms.Resize(SIZE),\n",
    "           transforms.RandomVerticalFlip(),\n",
    "           transforms.RandomHorizontalFlip(),\n",
    "           transforms.RandomRotation(90),\n",
    "           transforms.ToTensor(),\n",
    "           transforms.Normalize(mean=MEAN, std=STD)\n",
    "\n",
    "\n",
    "       ])\n",
    "\n",
    "\n",
    "image_transform_test = transforms.Compose([\n",
    "           transforms.Resize(SIZE),\n",
    "#             transforms.RandomVerticalFlip(),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "#             transforms.RandomRotation(90)\n",
    "           transforms.ToTensor(),\n",
    "           transforms.Normalize(mean=MEAN, std=STD)\n",
    "\n",
    "\n",
    "       ])\n",
    "gtrain = MultiBandMultiLabelDataset(df_train, base_path=PATH_TO_IMAGES, image_transform=image_transform_train)\n",
    "gtest = MultiBandMultiLabelDataset(df_test, base_path=PATH_TO_IMAGES, image_transform=image_transform_test)\n",
    "gsub = MultiBandMultiLabelDataset(df_submission, base_path=PATH_TO_TEST_IMAGES, train_mode=False, image_transform=image_transform_test)\n",
    "\n",
    "train_load = DataLoader(gtrain, collate_fn=gtrain.collate_func, batch_size=BS, num_workers=6)\n",
    "test_load = DataLoader(gtest, collate_fn=gtest.collate_func, batch_size=BS, num_workers=6)\n",
    "submission_load = DataLoader(gsub, collate_fn=gsub.collate_func, batch_size=BS, num_workers=6)\n",
    "\n",
    "model = get_resnet()\n",
    "device='cuda'\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "criterion = criterion.cuda()\n",
    "# evaluator = create_supervised_evaluator(model,\n",
    "#                                             device=device,\n",
    "#                                             metrics={'loss': Loss(criterion)\n",
    "#                                                     })\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad,model.parameters()), lr=0.00005)\n",
    "# trainer = create_supervised_trainer(model, optimizer, criterion, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.add_event_handler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "# train(trainer, train_load, test_load, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('/home/i008/model_1_0.1601224570123783.torch')\n",
    "\n",
    "# res = evaluate(model, test_load, threshold=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_predictions=predict_submission(model, submission_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the submission file and \n",
    "# THRESHOLD = 0.05\n",
    "# p = submission_predictions>THRESHOLD\n",
    "\n",
    "# submission_file = make_submission_file(sample_submission_df=df_submission,\n",
    "#                      predictions=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "neptune: Executing in Offline Mode.\n"
     ]
    }
   ],
   "source": [
    "from ignite.engine import create_supervised_trainer\n",
    "from torchvision.models import resnet\n",
    "from torch import nn\n",
    "from ignite.engine import Events\n",
    "import os \n",
    "\n",
    "def get_resnet(n_classes=27, resnet_version='resnet152', image_channels=4, pretrained=True):\n",
    "    \"\"\"\n",
    "    :param n_classes:\n",
    "    :param resnet_version in ['resnet152', 'resnet50', 'resnet18', 'resnet101']\n",
    "    :param image_channels:\n",
    "    :param pretrained:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert resnet_version in ['resnet' + str(i) for i in [18, 50, 101, 152]]\n",
    "    model = getattr(resnet, resnet_version)(pretrained=pretrained)\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "    inft = model.fc.in_features\n",
    "    model.fc = nn.Linear(in_features=inft, out_features=n_classes)\n",
    "    model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "    if image_channels is not 3:\n",
    "        model.conv1 = nn.Conv2d(image_channels, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                bias=False)\n",
    "\n",
    "    return model\n",
    "from neptune import Context\n",
    "\n",
    "neptune_context = Context()\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self, model,\n",
    "                 optimizer,\n",
    "                 criterion,\n",
    "                 train_loader,\n",
    "                 test_loader,\n",
    "                 device,\n",
    "                 epochs,\n",
    "                 checkpoint_directory='/home/i008/'\n",
    "        ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.criterion = criterion\n",
    "        self.device = device\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.trainer = create_supervised_trainer(model, optimizer, criterion, device)\n",
    "        self.epochs = epochs\n",
    "        self.checkpoint_directory = checkpoint_directory\n",
    "        self.epoch_end_loss = None\n",
    "        self.evaluator = create_supervised_evaluator(model, device=device, \n",
    "                                                metrics={'loss': Loss(criterion) })\n",
    "        \n",
    "        self.register_callbacks()\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        self.trainer.run(self.train_loader, max_epochs=self.epochs)\n",
    "\n",
    "    def register_callbacks(self):\n",
    "        self.trainer.add_event_handler(Events.ITERATION_COMPLETED, self._callback_store_training_loss)\n",
    "        self.trainer.add_event_handler(Events.EPOCH_COMPLETED, self._callback_store_training_results)\n",
    "        self.trainer.add_event_handler(Events.EPOCH_COMPLETED, self._callback_checkpoint)\n",
    "        self.trainer.add_event_handler(Events.EPOCH_COMPLETED, self._epoch_end_callback_log)\n",
    "        self.trainer.add_event_handler(Events.ITERATION_COMPLETED, self._batch_end_callback_log)\n",
    "        self.trainer.add_event_handler(Events.EPOCH_COMPLETED, self._batch_end_evaluate)\n",
    "        \n",
    "\n",
    "    def _callback_store_training_loss(self, engine):\n",
    "        self.current_epoch = engine.state.epoch\n",
    "        self.batch_end_loss = engine.state.output\n",
    "        self.batch_number = engine.state.iteration\n",
    "        \n",
    "         \n",
    "    def _callback_store_training_results(self, engine):\n",
    "        if self.test_loader is not None:\n",
    "            self.evaluator.run(self.test_loader)\n",
    "            metrics = self.evaluator.state.metrics\n",
    "            avg_nll = metrics['loss']\n",
    "            self.epoch_end_loss = avg_nll\n",
    "        \n",
    "    \n",
    "    def _callback_checkpoint(self, *args):\n",
    "        model_name = str(model).split('(')[0]\n",
    "        model_name += '_{}_{}'\n",
    "        model_path = os.path.join(self.checkpoint_directory, model_name).format(self.current_epoch, self.epoch_end_loss)\n",
    "        print(\"Storing model {}\".format(model_path))\n",
    "        save(self.model, model_path)\n",
    "        \n",
    "        \n",
    "    def _epoch_end_callback_log(self, *args):\n",
    "        neptune_context.channel_send('validation_loss_epoch_end', self.epoch_end_loss)\n",
    "        neptune_context.channel_send(\"epoch\", self.current_epoch)\n",
    "        print(\"Finished epoch {} with loss {}\".format(self.current_epoch, self.epoch_end_loss))\n",
    "            \n",
    "    def _batch_end_callback_log(self, *args):\n",
    "        neptune_context.channel_send('loss', self.batch_end_loss) \n",
    "        if self.batch_number % 100 == 0:\n",
    "            print(self.batch_end_loss, self.batch_number)\n",
    "        \n",
    "    def _batch_end_evaluate(self, *args):\n",
    "        def evaluate_f1(model, test_loader, threshold=0.2):\n",
    "            all_preds = []\n",
    "            true = []\n",
    "            model.eval()\n",
    "            for b in test_loader:\n",
    "                X, y = b\n",
    "                X, y = X.cuda(), y.cuda()\n",
    "                pred = model(X)\n",
    "                all_preds.append(pred.sigmoid().cpu().data.numpy())\n",
    "                true.append(y.cpu().data.numpy())\n",
    "\n",
    "\n",
    "            P = np.concatenate(all_preds)\n",
    "            R = np.concatenate(true)\n",
    "            \n",
    "            f_scores = []\n",
    "            for t  in [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3]:\n",
    "                f1 = f1_score(P>t, R, average='macro')\n",
    "                f_scores.append(f1)\n",
    "                \n",
    "            return f_scores\n",
    "                \n",
    "        self.f1_score = evaluate_f1(self.model, self.test_loader)\n",
    "        self.model.train()\n",
    "        \n",
    "        \n",
    "        print(\"Evaluation score is {}\".format(self.f1_score))\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlc = ModelTrainer(model, optimizer, criterion, train_load, test_load, device, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14000296592712402 100\n",
      "0.1540842354297638 200\n",
      "0.1747194081544876 300\n",
      "0.15312162041664124 400\n",
      "0.17220529913902283 500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-2:\n",
      "Process Process-1:\n",
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 90, in __getitem__\n",
      "    X = self._load_multiband_image(index)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 107, in _load_multiband_image\n",
      "    pil_channel = PIL.Image.open(p)\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 111, in _load_multiband_image\n",
      "    band4image = PIL.Image.merge('RGBA', bands=image_bands[:])\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 90, in __getitem__\n",
      "    X = self._load_multiband_image(index)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/Image.py\", line 2719, in merge\n",
      "    band.load()\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 90, in __getitem__\n",
      "    X = self._load_multiband_image(index)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 106, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/Image.py\", line 2580, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 90, in __getitem__\n",
      "    X = self._load_multiband_image(index)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/ImageFile.py\", line 235, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 90, in __getitem__\n",
      "    X = self._load_multiband_image(index)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 111, in _load_multiband_image\n",
      "    band4image = PIL.Image.merge('RGBA', bands=image_bands[:])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/Image.py\", line 2719, in merge\n",
      "    band.load()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/ImageFile.py\", line 219, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 90, in __getitem__\n",
      "    X = self._load_multiband_image(index)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 636, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 111, in _load_multiband_image\n",
      "    band4image = PIL.Image.merge('RGBA', bands=image_bands[:])\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/Image.py\", line 2719, in merge\n",
      "    band.load()\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 107, in _load_multiband_image\n",
      "    pil_channel = PIL.Image.open(p)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/Image.py\", line 2580, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "KeyboardInterrupt\n",
      "  File \"<ipython-input-1-affde06cbdac>\", line 107, in _load_multiband_image\n",
      "    pil_channel = PIL.Image.open(p)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/ImageFile.py\", line 219, in load\n",
      "    s = read(self.decodermaxblock)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/Image.py\", line 2580, in open\n",
      "    fp = builtins.open(filename, \"rb\")\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/PIL/PngImagePlugin.py\", line 636, in load_read\n",
      "    return self.fp.read(read_bytes)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2961, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-10-26cc0647907d>\", line 1, in <module>\n",
      "    mlc.train()\n",
      "  File \"<ipython-input-8-9aad6f51e451>\", line 58, in train\n",
      "    self.trainer.run(self.train_loader, max_epochs=self.epochs)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/ignite/engine/engine.py\", line 223, in run\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/ignite/engine/engine.py\", line 188, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/ignite/engine/engine.py\", line 210, in run\n",
      "    hours, mins, secs = self._run_once_on_dataset()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/ignite/engine/engine.py\", line 177, in _run_once_on_dataset\n",
      "    self._handle_exception(e)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/ignite/engine/engine.py\", line 188, in _handle_exception\n",
      "    raise e\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/ignite/engine/engine.py\", line 166, in _run_once_on_dataset\n",
      "    for batch in self.state.dataloader:\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 330, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 309, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/posixpath.py\", line 388, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/posixpath.py\", line 422, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "  File \"/home/i008/anaconda3/envs/genom/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 227, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 10884) exited unexpectedly with exit code 1. Details are lost due to multiprocessing. Rerunning with num_workers=0 may give better error trace.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "mlc.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "800 * 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:genom]",
   "language": "python",
   "name": "conda-env-genom-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
